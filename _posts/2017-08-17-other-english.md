---
layout:     post
title:      Daily English
author:     "Shane"
excerpt:    ""
header-img: "img/bg-mac.jpg"
tags:
    - Other
---

### DDIA
- underbralla term lump

### daily note
- caught everyone off guard 措手不及
- viable option 可行的方案
- let's start by talking about
- identify what each component is and explain how they interact with one another
- signify
- free up resources on backend servers which they can then devote to their main purpose, serving content
- malicious clients cannot access them directly to exploit any vulnerabilities
- scale the number of servers up and down to match fluctuations in traffic volume.
- Like we said
- eager beavour
- grunt work: routine, menial work.
- nuance, cancel out, annihilate, * distribute over +
- Punctuation: Question mark, Comma, Period, Exclamation mark, pound sign
- fabricated, agnostic, dictate, roster
- mathematically shorthand, roughly speaking
- resiliency, scalability, agility, flexability
- Answer the questions affirmatively
- **Consult** the formal definition and verify that
- shift left one unit
- examine different ways to see how **go through** the problem; Let me walk you through the problem
- A project is not usually regarded as a dispute or a contentious issue. You don't typically resolve a project, but you might resolve a problem within a project, as the project heads toward completion.
- **Tear down** stereotype and barriers.
- **Incredible how well versed** he is on all thing about digits. Not often you heard of a head of state talks about APIs.
- 我服你了
    - 说不过 Fine, you win | I surrender
    - 无语 I'm speechless | I have nothing to say
    - 钦佩 You blowed me away | I'm overwhelmed | That's impressive
- savvy, tally
- Eager learning spends the bulk of computational resources for model building.
- Compute the proximity value *individually* between the test and training examples.
- supply is way higher than demand.

### Narvar
- helper retailers **champion their customers** at every step of the journey
- a platform designed from the ground up to **drive long-term customer loyalty**. **deliver** post-purchase experiences that **retain, engage, and delight customers, from cart to doorstep, and beyond**.
- Convert: turn shoppers into happy customers throught clear expectations, personalized convenience, and relevant delivery options.
    - increase customer visibility and confidence.
    - maximize convenience by offering the right choices.
- Engage: keep them combing back with branded experiences and keep channels open for communication on their terms
    - deliver authentic experiences at every touchpoint.
    - build trust through relevant and proactive communication.
- Care: treat your customers with empathy. Combine a **human touch** with self-service experiences that **address their evolving needs**.
    - **enable seamless returns** and exchanges through convenience and choice
    - help your customers help themselves throught smart self-service options.
- Intelligence: get insight at scale. Machine learning applied to 3 billion interactions helps you understand trends and optimize your experience.
    - understancd your customer from preferences, to purchase hisotry and feedback
    - monitor trends, and otimize based on real-time performance and predictions

### Quantcast
- monetize users
- inform and shape their audience stories
- enable/empower your brand to grow
- grow business/revenue
- get accurate breakout of traffics, demographics, brand preference, shopping habits, customized to fit model

### Databricks
ai and big data are driving innovation across all industries. Innovation such as image recogonition, real time fraud detection and gene sequencing are changing the way business operate. I thought we **were well positioned to** achieve those innovations. Now I have a great team in place. Data engineers... Data scientist ... But It is challenging to **tranlate our efforts into product outcome**. We have different skill sets... We use diffrent tools making collebration harder. We spent 90% time with complex data pipelines and disjoint tools just to prepare data for analytics. **Security became an afterthought. Innovation was a distant dream.** Then we adopted the databricks, unified analytic platform. These **breakthrough** empowered my team to accelerate AI and innovation. It's unified management simplifies data engineering by enforcing data integrity and automating performance. Now my platform teams can make data available for analytics in near real time. It unifies people. Data engineers build data pipelines unifying both streaming and historical data. data scientist build model in one place while business users cosuming real-time dashboard. Databrickes is service. We don't have to manually configure and scale clusters. It's cloud based and for we managed. And enterprise security ensures data is protected.

### 5902
Claim, belive, agree, show, think, belive,suggest<br>
Criticize, describe, identify, summarize, examine, discuss<br>
Argue, point out, realize, explain, assert, acknowledge, admit, maintain, emphasize<br>

Presents the two cause<br>
Identify the correctness<br>
He thinks when to start work matters<br>
He claimed what the other researchers dicovered was inaccurate

有人不同意，但是作者极力解释 
Argues that; Asserts that

对作者的表述感到疑惑
Claims that; Contends that; Maintains that; Insists that; States that

But she demands high on you. Thus it was definitely not meant for the faint-hearted<br>
learning curve is very deep<br>
that's relief 如释重负<br>
it save my minds 这样比较简单<br>
'darn' 'yikes'<br>
it would complaint about it 编译器会抱怨它<br>
rush this out<br>

### 公共场合
Leave personal belongings doens't reserve the room 个人物品<br>
Be considerate of others and do not monopolize the room 考虑周到 垄断<br>
Invite theft 引入小偷<br>
pose a security for everyone<br>

### whimspy dairy
- The thing what really stinks me is that ... 让我恶心的事
- get into sb 整天和某人在一起
- stick with sb 厮混
- hive right around the 150 mark 在150名左右浮动
- move up one spot 提高一名
- scramble the spot 竞争排名
- it gets in one ear and out the other with him. 耳边风
- have only come around in the last couple of years. 才来了几年

### Cover Letter

This email can be broken into 3 parts. Subject line, email body and the resume attachment.

The subject line needs to be simple, clear and catch their attention. The content should indicate where you saw the posting, how you came by their direct contact info, and a brief pitch about why you would be a good fit for the role. Lastly, always include a resume attachment. This indicates that you know not to waste their time. It is considered a waste of time if they have to reply to your email to request for your resume. Recruiters would much rather open your resume, skim through it, and determine whether they would like to set up an interview with you right on the spot.

Here are examples for each piece of the email.

**Subject:**

XXFullName application for XXJobTitle XXJobID - Resume Attached

**Email body:**

Hi XX,

I came accross the software engineer role at XXcompany and am interested in applying. I found your contact info via LinkedIn so thought to reach out to you directly. I appreciate you taking the time to consider my application.

Short paragraph on why the company and why you are a great fit for the role.

Best regards,

XXFullName

XXPhone

**Attachment:**

Attach a well formatted, easy to skim resume that contains no spelling or grammatical errors.

Do keep in mind that recruiters receive hundreds of applications from multiple sources so emailing them directly may not always get you a response. It could get lost in all the noise. Deploying this simple and to the point methodology, however, will maximize your likelihood of getting a reply. If you do not hear back within a week, definitely do send a follow up email or try other ways to get your application noticed.

agility fuel iginte scrap idea

### data mining 写作
This section examines some statistical tests available to compare the difference between two classifiers.

**For illustrative purposes**, **consider** a pair of classification models... **Suppose** MA achieves 85% accuracy when evaluated on a set DA with size nA. **Based on this information**, ..?
The preceding example **raises two key quesions regarding** the statistical significance of the performance metrices.

1. Hom much confidence intervals should be placed on the acc. of Ma?
2. Is it possible to explain **the observed difference in acc.** as a result of **the variation in the composition** of the test sets?

The first quesiont **relates to the issue of estimating** the confidence interval. The seconde questions relates to the issue of testing the staticical siginificance of the observed deviation. These issues are invesitigated in the remainder of this section.

To determine the confidence interval, we have to establish the probability distribution that governs acc measure. This section describe an approach of deriving the confidence interval by modeling the classificaton task as a binomial experiment. Following is a list of characters of a binomail experiment.

### LinkedIn
[example 1](https://www.linkedin.com/in/nishanthgandhidoss/)

[example 2](https://www.linkedin.com/in/avinash-radhakrishnan-2519819a/)

[example 3](http://blog.dennybritz.com/about/)

**self introduction**<br>
I **completed** my Masters to **specialize myself in the field of** Data Science **with concentration in** Applied Deep learning for Artificial Intelligence.
•   Gathered external data to analyze market strategies using exploratory data analysis and regression methods.
•   Identified and examined industry and geographic trends to increase regional sales by 10%.
•   Reduced production defects to half by means of shift, operator, produced part and inspection report details using R.
•   Enhanced productivity by developing a Web-based Barcode ERP system using Java spring MVC, jQuery.
•   Analysed the rejection quantity data to improve the inspection process thereby achieving maximum customer satisfaction.
•   Enhanced productivity by developing a Web-based Barcode ERP system.
•   Interacted with senior management to understand the requirement and also providing IT solutions to develop an ERP system.
•   Worked on the production line to have a closer understanding of the production workflow to improve the backtracking system functionality


**recommendation**<br/>
Nishanth joined our team for a summer internship. Due to his specialization in Deep Learning, we were glad to have him tackle handwritten digit recognition, a difficult and open problem we had; and Nishanth in the short few months of internship developed a full protoype of a system using image processing for segmentation and CNNs for digit recognition. From the first day on he was determined to deliver great value, and was very organized and independent. Over the course of his internship, he was totally open to feedback and not just took it to heart, but immediately acted and improved on it. So in summary, he not just did a great job researching both modern and traditional methods, he developed a great sense of what works for the business, breaking down the larger task into manageable pieces and collaborating with the team to achieve these goals. More than that, he was always proactive in reaching out whenever he saw an opportunity to connect and learn, and put a lot of effort into very successful presentations to the team, and made tremendous strides in targeting communication to differing audience.
Overall, it was a joy having Nishanth as an intern, and we'd be happy to have him back!

Nishanth is a energetic and skilled individual, with broad skills in data science. His capabiities range from database, web, and application development to analytics and data visualization. More importantly, he has a combination of a curious mind eager to learn new things and an incredible work ethic. He will be an asset to any team or company.

Nishanth is a quick learner and adapted himself in the project in a short span when he joined as an entry level analyst. He possesses a strong technical knowledge on Full Stack Web development and data analytics which helped him grow with the team. He is a good team player where he mentored his juniors to the path of success and well-committed person to rely on for any deliverable. He is always organized, goal oriented and dedicated to meet high customer satisfaction rate. Nishanth would be an asset to any team, and I wish him all success in his life endeavors.

Nishanth is a proficient developer come mentor. I have worked on several projects with him over the span of 6 years where he proved time and again that he can emerge from a complex situation, he is cool headed in handling complex and delicate situations. He also has good experience in working on multiple projects simultaneously. His deep knowledge and professional experience in the field of Big data and Full Stack Web development is always impressive. I wish all good happens to him and reach great heights in future.

Nishanth is one of the hardest working students I've ever met. He takes the initiative to gain new knowledge and pursue solutions to complex problems. He will take a basic problem statement and use it as an opportunity to discover advanced problem solving skills. His communication skills are also exemplary. Nishanth will be an asset to any organization striving to find the value proposition in big data.

### Kafka Introduce
this kind of thing led us to the rat's nest of intergration complexity.

use event instead of table as the source of the truth of the state of the system. hook A up to B. Look the system of the truth as being the actual events and keep those around.

Go back in time. **rewind back where we left off** or reproduce some of these events. That thing needs to not just be an event stream but it also needs to be a ledger, a ledger that we can go back in time. 

**distibuteded from the outset**.

Why not message systems?<br>
Ordering, is ordering always **guranteed all the way to the consumption side** in message system? <br>
Horizontal scaling?<br>
Push. Back pressure<br> 

it's distriubted by nature and it's redundant so it's creating copies of these events as they go.

event ledger, distributed, redundant. a distributed commit log.

Kafka fundamentals: durability and ordering guaranteed. cluster is core. Message queue semantics.

**come into play**. let's go through some of those. So first is modern ETL, CDC(change data capture).

Record: key, value, timestamp. immutable, append-only, persisted (do everything in disk)

broker: node in the cluster
producer: write record to a broker
consumer: read record from a broker
cluster: leader-follower for cluster distribution
topic: logical name with 1 or more partitions.
partition: replicated, ordering is only guaranteed in a partition. Partitioning can be done manually or based on a key.
offset: unique sequetial id per partition. Consumer instances need to only keep track of the offsets. 

producer partitioning: each partition has one lead server and has zero or more follower server. Write and Read are all done in leader.  Replication factor is based on topic. (when you produce a message to a topic, essentially it just do something like a round robin accross the partition) auto-rebalancing. 

consumer groups: each partition is consumed by exactly one consumer in the group. Message consumption is balanced across all consumers in a group. 

quorum, dramatic impact, do the right, confluent console

### Gaurav Sen
Imagine an appplication which **reaches out** millions of users. Request on the server should never fail even if theres is a hardware failure. Thus we should have multiple copies of servers in the system and redirect requests to available servers. We should make sure information in each server is the same. This is important because the user should not **get contradicting information** when their requests is **relayed** by the load balancer and served on different servers over time.

The difference between cloud and desktop is **nothing really**. Could is a set of computers. You pay cloud solution providers and they give you computation power. Computation power **is nothing but a desktop that they have somewhere** and run your algorithm. **The reason we like to do this** is because the configuration and the reliability can **be taken care of to a large extent by clouder solution providers**. 

### Microservices are bad
Microservices are the current hot software fad, but otherwise a useless idea. Like all the previous fads in software, e.g. structured programming, OOP etc, it falsely assumes, that you can decompose the software into meaningful isolated units, preferably with three-like dependencies between them. The reality or course is, that you can't do that and moreover, you actually don't want that either. Whenever it makes any sense business wise to connect the existing independent services, then you connect them. A complex software system is just more valuable and to increase the value of the system you have to make it more complex. The conclusion is, that any approach to software, that assumes a simple structure (architecture), is doomed to fail.﻿

### Uber Service
Location indexing<br>
so let's start by first talking about ...

1. Current location points for all cars
2. Fast queries by location
3. filter by car properties
4. high volume of reads and writes
5. high ephemeral time sentive, so we don't need long-term storage. 
All of these requirements put together suggerst that we should build in memory search index.

Location storage

 













